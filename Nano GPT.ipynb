{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "#This GPT model is inspired by original paper \"Attention is all you need\". It doesn't contain the encoder which means it's a decoder only transformer and also it doesn't contain the cross-attention block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AyRtIEZg_1K2",
    "outputId": "61fcd6b4-f3ca-4270-b127-3653f6847d48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('input.txt', <http.client.HTTPMessage at 0x28b7fdf55b0>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "import urllib.request\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "local_filename = \"input.txt\"\n",
    "urllib.request.urlretrieve(url, local_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "KgWjfcbkAFVn"
   },
   "outputs": [],
   "source": [
    "# Reading the whole file in a go\n",
    "with open('input.txt', 'r') as f:\n",
    "  text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzQOL51ZCZdj",
    "outputId": "d81ec771-75d8-4e9d-df6b-eb858228b249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "# To check first 500 char\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwhVzyXvChC8",
    "outputId": "f435da25-3227-4730-f666-57565b0b697d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of characters is 1115394\n"
     ]
    }
   ],
   "source": [
    "total_char_length = len(text)\n",
    "print(f\"The length of characters is {total_char_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k1t-kx8jC2X5",
    "outputId": "e4095321-8de9-4fae-fd87-c2ff312b020e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "The vocab size is 65\n"
     ]
    }
   ],
   "source": [
    "char = sorted(list(set(text)))\n",
    "vocab_size = len(char)\n",
    "print(\"\".join(char)) #checking all characters present in data\n",
    "print(f\"The vocab size is {vocab_size}\") #total size of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umxtLrGiSmuL",
    "outputId": "284a0ce7-25c2-40e1-db31-04e62211b7ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
      "{0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
     ]
    }
   ],
   "source": [
    "#Tokenizing\n",
    "stoi = {ch:i for i,ch in enumerate(char)} #Mapping for char to integer\n",
    "print(stoi)\n",
    "itos = {i:ch for i,ch in enumerate(char)}\n",
    "print(itos)\n",
    "#Encoding from string to integer\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "#Decoding from integer to string\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQp-kcL5Ub_x",
    "outputId": "7e86c90d-f7a4-41bd-988b-44665fc9160d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53]\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"hello\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXbV5dPaVrFn",
    "outputId": "8124af8e-8943-4a63-9d99-f545ef126444"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(decode([46, 43, 50, 50, 53]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rao_d\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\rao_d\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\rao_d\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\rao_d\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\rao_d\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rao_d\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\rao_d\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rao_d\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rao_d\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rao_d\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "OXaF1TOZWDM9"
   },
   "outputs": [],
   "source": [
    "#Encoding the entire text data and storing into a tensor\n",
    "import torch\n",
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVSxfh_ncO9b",
    "outputId": "8d73e9a2-3cbe-401c-ff59-e32f4e029b1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, data.dtype) #Checking shape and type of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FT7JrlYncUgT",
    "outputId": "1c9039e1-44fb-4c00-d38d-8206d857bc9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "#Tensor Sequence for first 500 char\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "CQD95ZNjcYF-"
   },
   "outputs": [],
   "source": [
    "#Splitting data into test and validation\n",
    "n = int(0.9*len(data)) #Splitting data\n",
    "train_data = data[:n] #90% data is for training\n",
    "val_data = data[n:] #10% is for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emOgBf8-Lju6",
    "outputId": "97950a87-3d8a-4d7c-f12c-b59d5e15cfae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 #Chunk size\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U31aohRnLvj6",
    "outputId": "5e52c176-cad4-4d2f-cf13-bc6075dcbf13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([18]) the output is 47\n",
      "When input is tensor([18, 47]) the output is 56\n",
      "When input is tensor([18, 47, 56]) the output is 57\n",
      "When input is tensor([18, 47, 56, 57]) the output is 58\n",
      "When input is tensor([18, 47, 56, 57, 58]) the output is 1\n",
      "When input is tensor([18, 47, 56, 57, 58,  1]) the output is 15\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15]) the output is 47\n",
      "When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the output is 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "  context = x[:t+1]\n",
    "  target = y[t]\n",
    "  print(f\"When input is {context} the output is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41u6sXI9O9-K",
    "outputId": "851d96a9-6519-419e-e46f-c023c8f5d0ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "----\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 43\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 5\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 57\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 1\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 46\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 43\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 39\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 53\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 56\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 1\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 46\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 39\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 1\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 1\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 46\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 39\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 58\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 1\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 46\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 17\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 27\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 10\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 0\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 21\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 1\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 54\n",
      "when input is [18, 47, 56, 57, 58, 1, 15, 47] the target: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "  data = train_data if split=='train' else val_data\n",
    "  ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "  return x,y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size):\n",
    "  for t in range(block_size):\n",
    "    content = xb[b, :t+1]\n",
    "    target = yb[b, t]\n",
    "    print(f\"when input is {context.tolist()} the target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "LbTVIBFamLlh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
      "wnYWmnxKWWev-tDqXErVKLgJ\n"
     ]
    }
   ],
   "source": [
    "#Implementing Bigram Language model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "  def __init__(self, vocab_size):\n",
    "    super().__init__()\n",
    "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "  \n",
    "  def forward(self, idx, targets=None):\n",
    "    logits = self.token_embedding_table(idx) #Batch, Time, Chanel\n",
    "    if targets is None:\n",
    "        loss = None\n",
    "    else:\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(B*T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "    return logits, loss\n",
    "\n",
    "  def generate(self, idx, max_new_tokens): \n",
    "    #idx is B,T array of indices in current context\n",
    "    for _ in range(max_new_tokens):\n",
    "      logits, loss = self(idx) #get predictions\n",
    "      logits = logits[:, -1, :] # focus only on last time step becomes B,C\n",
    "      probs = F.softmax(logits, dim=-1) #applying softmax to get probability\n",
    "      idx_next = torch.multinomial(probs, num_samples=1) #sample from distribution\n",
    "      idx = torch.cat((idx, idx_next), dim=1) #append sample index to running sequence\n",
    "    return idx\n",
    "  \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "KDrNgPBZmLop"
   },
   "outputs": [],
   "source": [
    "#creating a Pytorch optimzer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.382369041442871\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for step in range(10000):\n",
    "    #sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    #evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lso br. ave aviasurf my, yxMPZI ivee iuedrd whar ksth y h bora s be hese, woweee; the! KI 'de, ulseecherd d o blllando;LUCEO, oraingofof win!\n",
      "RIfans picspeserer hee tha,\n",
      "TOFonk? me ain ckntoty ded. bo'llll st ta d:\n",
      "ELIS me hurf lal y, ma dus pe athouo\n",
      "BEY:! Indy; by s afreanoo adicererupa anse tecorro llaus a!\n",
      "OLeneerithesinthengove fal amas trr\n",
      "TI ar I t, mes, n IUSt my w, fredeeyove\n",
      "THek' merer, dd\n",
      "We ntem lud engitheso; cer ize helorowaginte the?\n",
      "Thak orblyoruldvicee chot, p,\n",
      "Bealivolde Th li\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1,1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#version 1 - Avg. past context with for loops [Weak Aggregation]\n",
    "xbow = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b,:t+1]\n",
    "        xbow[b,t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 2 - Using Matrix Multiplication\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei/wei.sum(1, keepdim=True)\n",
    "xbow2 = wei@x #(B, T, T) @ (B, T, C) --> (B, T, C)\n",
    "torch.allclose(xbow, xbow2, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 3 - using softmax\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "xbow3 = wei@x\n",
    "torch.allclose(xbow,xbow3, atol = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#version 4 - self-attention\n",
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 32 #Batch, Time, Chanel\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "#single head performing self-attention (Attention is basically a communication mechanism)\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k= key(x) #(B, T, 16)\n",
    "q = query(x) #(B, T, 16)\n",
    "wei = q@k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "#wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "v = value(x)\n",
    "out = wei@v\n",
    "# out = wei@x\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "        [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "        [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2363e-08)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.abs(xbow - xbow2)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]),\n",
       " tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0], xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8077e-01, -6.9988e-02, -3.5962e-01, -9.1520e-01,  6.2577e-01,\n",
       "          2.5510e-02,  9.5451e-01,  6.4349e-02,  3.6115e-01,  1.1679e+00,\n",
       "         -1.3499e+00, -5.1018e-01,  2.3596e-01, -2.3978e-01, -9.2111e-01,\n",
       "          1.5433e+00,  1.3488e+00, -1.3964e-01,  2.8580e-01,  9.6512e-01,\n",
       "         -2.0371e+00,  4.9314e-01,  1.4870e+00,  5.9103e-01,  1.2603e-01,\n",
       "         -1.5627e+00, -1.1601e+00, -3.3484e-01,  4.4777e-01, -8.0164e-01,\n",
       "          1.5236e+00,  2.5086e+00],\n",
       "        [-6.6310e-01, -2.5128e-01,  1.0101e+00,  1.2155e-01,  1.5840e-01,\n",
       "          1.1340e+00, -1.1539e+00, -2.9840e-01, -5.0754e-01, -9.2392e-01,\n",
       "          5.4671e-01, -1.4948e+00, -1.2057e+00,  5.7182e-01, -5.9735e-01,\n",
       "         -6.9368e-01,  1.6455e+00, -8.0299e-01,  1.3514e+00, -2.7592e-01,\n",
       "         -1.5108e+00,  2.1048e+00,  2.7630e+00, -1.7465e+00,  1.4516e+00,\n",
       "         -1.5103e+00,  8.2115e-01, -2.1153e-01,  7.7890e-01,  1.5333e+00,\n",
       "          1.6097e+00, -4.0323e-01],\n",
       "        [-8.3447e-01,  5.9780e-01, -5.1406e-02, -6.4559e-02, -4.9701e-01,\n",
       "          4.6576e-01, -2.5726e-01, -1.0673e+00,  2.0089e+00, -5.3698e-01,\n",
       "          2.2280e-01,  6.9705e-01, -1.4267e+00,  9.0594e-01,  1.4459e-01,\n",
       "          2.2800e-01,  2.4900e+00, -1.2237e+00,  1.0107e+00,  5.5600e-01,\n",
       "         -1.5935e+00, -1.2706e+00,  6.9033e-01, -1.9614e-01,  3.4491e-01,\n",
       "         -3.4189e-01,  4.7587e-01, -7.6634e-01, -4.1896e-01, -4.3699e-01,\n",
       "         -1.0012e+00, -4.0943e-01],\n",
       "        [-1.6669e+00, -1.3651e+00, -1.6552e-01,  9.6225e-01,  3.1549e-02,\n",
       "         -7.4190e-01, -2.9779e-01,  1.7166e-02, -1.7722e-01, -1.3343e-01,\n",
       "          2.9396e-01,  1.3850e+00,  1.2091e-01,  2.5418e+00, -6.4046e-01,\n",
       "         -1.9740e+00, -3.2957e-01,  7.9589e-03,  9.2623e-01, -1.8846e+00,\n",
       "          1.6696e-01,  4.5862e-01, -1.7662e+00,  5.8599e-01,  1.7510e+00,\n",
       "          2.8072e-01,  3.1096e-01, -6.5376e-01, -6.5763e-01,  3.1845e-01,\n",
       "         -5.4959e-01, -1.4649e+00],\n",
       "        [-2.0555e+00,  1.8275e+00,  1.3035e+00, -4.5013e-01,  1.3471e+00,\n",
       "          1.6910e+00, -1.2445e-01, -1.6824e+00, -2.6608e-02,  7.4049e-02,\n",
       "          1.0517e+00,  6.7789e-01,  3.0665e-01, -7.4723e-01,  7.4349e-01,\n",
       "          8.8766e-01,  2.2874e+00,  9.6114e-01, -1.5297e+00, -2.9122e-01,\n",
       "         -1.1395e-01, -3.1367e-01, -6.2931e-01,  1.1385e+00, -9.9127e-01,\n",
       "          1.6999e-01,  1.2249e+00, -2.3454e-01, -1.0572e+00, -6.5427e-01,\n",
       "          1.5909e+00, -6.9949e-01],\n",
       "        [-8.9606e-01,  6.6191e-02, -5.6280e-02,  2.3412e+00, -2.7234e+00,\n",
       "          5.0967e-01, -8.1447e-01, -2.4604e-01,  4.5085e-03,  2.0474e+00,\n",
       "         -1.5755e-01, -2.1867e-01, -1.3519e+00, -5.7281e-02, -1.8540e+00,\n",
       "         -1.3849e+00, -3.4540e-01, -1.1625e+00,  1.4448e-01,  1.6632e-01,\n",
       "          7.5070e-01,  9.1317e-01, -1.7277e+00,  1.3055e+00,  9.5932e-01,\n",
       "          1.0600e+00,  6.2986e-01, -1.2867e+00, -6.8748e-01,  2.1382e+00,\n",
       "          5.1141e-01,  1.2191e+00],\n",
       "        [ 1.9098e-01, -3.4251e-01,  1.7955e+00,  1.3915e+00,  1.0785e+00,\n",
       "         -6.1495e-01, -4.5885e-01,  5.6748e-01,  1.8289e-02, -1.6608e+00,\n",
       "          1.1169e+00,  5.1965e-01, -1.2423e+00, -9.6182e-01, -8.4998e-02,\n",
       "          1.1854e-01,  2.9843e-01, -7.2636e-01, -3.1187e-01, -4.5604e-01,\n",
       "          6.4407e-01,  6.0728e-01,  1.2397e+00,  7.3249e-01,  5.0418e-01,\n",
       "          8.7135e-01, -2.7416e-01, -7.4689e-01, -5.8324e-01,  3.6988e-01,\n",
       "         -5.5562e-01, -3.9828e-01],\n",
       "        [-5.8188e-01, -2.2083e-01,  1.3537e-02, -3.0574e-01, -3.0384e-02,\n",
       "          8.2161e-01,  3.8670e-04, -4.4742e-01,  8.2040e-01, -1.5178e+00,\n",
       "          6.1587e-01, -1.8648e+00, -9.7773e-01,  6.3224e-02, -4.5483e-01,\n",
       "         -4.1474e-01,  1.4987e+00, -3.9867e-02, -8.0510e-01, -1.1624e+00,\n",
       "          4.2716e-01, -2.8192e-01, -1.2773e-02, -8.7792e-01, -3.2248e-01,\n",
       "          1.8299e-01, -9.3030e-01, -1.2488e+00,  1.1192e+00, -1.9079e+00,\n",
       "         -5.2756e-01,  1.0807e+00]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# a = torch.ones(3, 3)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a = a/torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a@b\n",
    "print(\"a=\")\n",
    "print(a)\n",
    "print(\"--\")\n",
    "print(\"b=\")\n",
    "print(b)\n",
    "print(\"--\")\n",
    "print(\"c=\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "      xmean = x.mean(1, keepdim=True) # batch mean\n",
    "      xvar = x.var(1, keepdim=True) # batch variance\n",
    "      xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "      self.out = self.gamma * xhat + self.beta\n",
    "      # update the buffers\n",
    "      return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = BatchNorm1d(100)\n",
    "x = torch.randn(32,100) #batch size 32 with 100 dimensional vetor\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
