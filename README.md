# NanoGPT

This GPT model is inspired by the original paper "Attention is all you Need". It doesn't contain the encoder which means it is a Decoder only transformer and also it doesn't have the cross-attention block